{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Name : S.SANJTIH***\n",
    "\n",
    "***ID NO : 190562G***\n",
    "\n",
    "***Course Code : EN2550***\n",
    "### **CNNs and Transfer Learning**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import sys\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "lib_dir=\"E:\\Coding\\Computer Vision\\cv-libs\"\n",
    "sys.path.append(lib_dir)\n",
    "from show_images import show_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{01}.$ Implementation of the LeNet5 network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape :  (60000, 32, 32)\n",
      "Train Labels Shape :  (60000,)\n",
      "Test Images Shape : 0 (10000, 32, 32)\n",
      "Test Labels Shape : 0 (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Padding\n",
    "padding = tf.constant([[0, 0], [2, 2], [2, 2]])\n",
    "train_images = tf.pad(train_images, padding, constant_values=0)\n",
    "test_images = tf.pad(test_images, padding, constant_values=0)\n",
    "\n",
    "print(\"Train Images Shape : \", train_images.shape)\n",
    "print(\"Train Labels Shape : \", train_labels.shape)\n",
    "print(\"Test Images Shape : 0\", test_images.shape)\n",
    "print(\"Test Labels Shape : 0\", test_labels.shape)\n",
    "class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "train_images=tf.dtypes.cast(train_images,tf.float32)\n",
    "test_images=tf.dtypes.cast(test_images,tf.float32)\n",
    "train_images,test_images=train_images[...,np.newaxis]/255.0,test_images[...,np.newaxis]/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6,(5,5),activation=\"relu\",input_shape=(32,32,1)))\n",
    "model.add(layers.AveragePooling2D(2,2))\n",
    "model.add(layers.Conv2D(16,(5,5),activation=\"relu\"))\n",
    "model.add(layers.AveragePooling2D(2,2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120,activation='relu'))\n",
    "model.add(layers.Dense(84,activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0294 - accuracy: 0.9905\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0227 - accuracy: 0.9927\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0181 - accuracy: 0.9944\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0119 - accuracy: 0.9962\n",
      "313/313 - 3s - loss: 0.0335 - accuracy: 0.9903 - 3s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,epochs=5)\n",
    "test_loss,train_loss=model.evaluate(test_images,test_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3600x360 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_display=[]\n",
    "for i in range(10):\n",
    "    img_array = tf.keras.utils.img_to_array(test_images[i])\n",
    "    img_array = tf.expand_dims(img_array, 0) \n",
    "    predictions = model.predict(img_array)\n",
    "    images_display.append([test_images[i],(np.min(test_images[i]),np.max(test_images[i])),np.argmax(predictions[0])])\n",
    "show_images(images_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{02}.$ Implementation of CNN for CIFAR10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Question 02 --- > CIFAR10\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalizing the values\n",
    "train_images, test_images = train_images/255, test_images/255\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 28, 28, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,570\n",
      "Trainable params: 226,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.4971 - accuracy: 0.4555\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 1.1162 - accuracy: 0.6059\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9538 - accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.8387 - accuracy: 0.7059\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.7548 - accuracy: 0.7369\n",
      "313/313 - 3s - loss: 0.8394 - accuracy: 0.7155 - 3s/epoch - 11ms/step\n",
      "0.715499997138977\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(5,5),activation='relu',input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(train_images,train_labels,epochs=5)\n",
    "test_loss,test_acc=model.evaluate(test_images,test_labels,verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted Model :  dog\n"
     ]
    }
   ],
   "source": [
    "# class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "photo_no=3450\n",
    "plt.imshow(test_images[photo_no])\n",
    "plt.show()\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(test_images[photo_no])\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "predictions = model.predict(img_array)\n",
    "print(\"Predicted Model : \",class_names[np.argmax(predictions[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{03}.$ Implementation of given network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Padding\n",
    "padding = tf.constant([[0, 0], [2, 2], [2, 2]])\n",
    "train_images = tf.pad(train_images, padding, constant_values=0)\n",
    "test_images = tf.pad(test_images, padding, constant_values=0)\n",
    "\n",
    "class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "train_images=tf.dtypes.cast(train_images,tf.float32)\n",
    "test_images=tf.dtypes.cast(test_images,tf.float32)\n",
    "train_images,test_images=train_images[...,np.newaxis]/255.0,test_images[...,np.newaxis]/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,994\n",
      "Trainable params: 121,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1307 - accuracy: 0.9590\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0413 - accuracy: 0.9876\n",
      "313/313 - 3s - loss: 0.0280 - accuracy: 0.9904 - 3s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model_base = models.Sequential()\n",
    "model_base.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(32,32,1)))\n",
    "model_base.add(layers.MaxPool2D(2,2))\n",
    "model_base.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model_base.add(layers.MaxPool2D(2,2))\n",
    "model_base.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model_base.add(layers.Flatten())\n",
    "model_base.add(layers.Dense(64,activation='relu'))\n",
    "model_base.add(layers.Dense(10))\n",
    "\n",
    "model_base.compile(optimizer=keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "print(model_base.summary())\n",
    "\n",
    "model_base.fit(train_images,train_labels,epochs=2)\n",
    "test_loss,test_acc=model_base.evaluate(test_images,test_labels,verbose=2)\n",
    "model_base.save_weights('saved_weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{04}.$ Loading the weights saved into another model and training for two more epochs...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,994\n",
      "Trainable params: 121,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0291 - accuracy: 0.9909\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "313/313 - 3s - loss: 0.0262 - accuracy: 0.9920 - 3s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_lw = models.Sequential()\n",
    "model_lw.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(32,32,1)))\n",
    "model_lw.add(layers.MaxPool2D(2,2))\n",
    "model_lw.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model_lw.add(layers.MaxPool2D(2,2))\n",
    "model_lw.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model_lw.add(layers.Flatten())\n",
    "model_lw.add(layers.Dense(64,activation='relu'))\n",
    "model_lw.add(layers.Dense(10))\n",
    "\n",
    "model_lw.compile(optimizer=keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "print(model_lw.summary())\n",
    "\n",
    "model_lw.load_weights('saved_weights/')\n",
    "\n",
    "model_lw.fit(train_images,train_labels,epochs=2)\n",
    "test_loss,test_acc=model_lw.evaluate(test_images,test_labels,verbose=2)\n",
    "\n",
    "model_lw.save('saved_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{05}.$ Loading above model...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,994\n",
      "Trainable params: 121,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "313/313 - 2s - loss: 0.0331 - accuracy: 0.9903 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03310105949640274, 0.9902999997138977]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Model\n",
    "model_ld = keras.models.load_model('saved_model/')\n",
    "print(model_ld.summary())\n",
    "model_ld.evaluate(test_images,test_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{06}.$ Replacing last layer with fresh dence layer of 10 output nodes and train for two epchos...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25_input (InputLayer  [(None, 32, 32, 1)]      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,994\n",
      "Trainable params: 121,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0695 - accuracy: 0.9830\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0083 - accuracy: 0.9976\n",
      "313/313 - 3s - loss: 0.0262 - accuracy: 0.9920 - 3s/epoch - 10ms/step\n",
      "0.9919999837875366\n"
     ]
    }
   ],
   "source": [
    "base_inputs = model_ld.layers[0].input\n",
    "base_outputs = model_ld.layers[-2].output\n",
    "output = layers.Dense(10)(base_outputs)\n",
    "\n",
    "new_model = keras.Model(inputs=base_inputs,outputs=output)\n",
    "new_model.compile(optimizer=keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "print(new_model.summary())\n",
    "\n",
    "\n",
    "new_model.fit(train_images,train_labels,epochs=2)\n",
    "test_loss,test_acc=model_lw.evaluate(test_images,test_labels,verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{07}$. Transfer Learning : Making the loaded layers as untrainable and repeat above process...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28_input (InputLayer  [(None, 32, 32, 1)]      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,994\n",
      "Trainable params: 650\n",
      "Non-trainable params: 121,344\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2102 - accuracy: 0.9499\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "313/313 - 3s - loss: 0.0262 - accuracy: 0.9920 - 3s/epoch - 10ms/step\n",
      "Test Accuracy :  0.9919999837875366\n"
     ]
    }
   ],
   "source": [
    "model_for_tl = keras.models.load_model('saved_model/')\n",
    "model_for_tl.trainable = False\n",
    "for layers in model_for_tl.layers:\n",
    "    assert layers.trainable == False\n",
    "\n",
    "\n",
    "base_inputs = model_for_tl.layers[0].input\n",
    "base_outputs = model_for_tl.layers[-2].output\n",
    "output = layers.Dense(10)(base_outputs)\n",
    "\n",
    "\n",
    "new_model = keras.Model(inputs=base_inputs,outputs=output)\n",
    "new_model.compile(optimizer=keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "print(new_model.summary())\n",
    "\n",
    "\n",
    "new_model.fit(train_images,train_labels,epochs=2)\n",
    "test_loss,test_acc=model_lw.evaluate(test_images,test_labels,verbose=2)\n",
    "print(\"Test Accuracy : \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$Q_{08}.$ Load a pre-trained ResNet model. Connect an output layer of 5 nodes. Feed arrays of random numbers of input images and transfer learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Question 02 --- > CIFAR10\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalizing the values\n",
    "train_images, test_images = train_images/255, test_images/255\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print(train_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_31 (MaxPooling2D  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_31[0][0]',       \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooling2D  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_32[0][0]',       \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_33 (MaxPooling2D  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_33[0][0]',       \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 5)            10245       ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,575,045\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "32/32 - 81s - loss: 33.3859 - accuracy: 0.1890 - 81s/epoch - 3s/step\n",
      "Epoch 2/3\n",
      "32/32 - 62s - loss: 8.9940 - accuracy: 0.1930 - 62s/epoch - 2s/step\n",
      "Epoch 3/3\n",
      "32/32 - 63s - loss: 6.9309 - accuracy: 0.1860 - 63s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17df9da12b0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tl=keras.applications.resnet_v2.ResNet50V2()\n",
    "\n",
    "model_tl.trainable=False\n",
    "for layer in model_tl.layers:\n",
    "    assert layer.trainable==False\n",
    "\n",
    "base_innputs=model_tl.layers[0].input\n",
    "base_ouputs=model_tl.layers[-2].output\n",
    "output=layers.Dense(5)(base_ouputs)\n",
    "\n",
    "model_tl=keras.Model(inputs=base_innputs,outputs=output)\n",
    "model_tl.compile(optimizer=keras.optimizers.Adam(),loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "print(model_tl.summary())\n",
    "\n",
    "train_images=np.random.randint(0,256,(1000,224, 224, 3))\n",
    "train_labels=np.random.randint(0,5,1000)\n",
    "\n",
    "model_tl.fit(train_images,train_labels,epochs=3,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8d7b6eb1a9ce00d238716e1cf8ea41c8ac6d54f4c249f9b109b98a35ae0e964"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
